apiVersion: v1
kind: ConfigMap
metadata:
  name: accumulo-configmap
  labels:
    app: {{ template "accumulo.name" . }}
    chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  accumulo-env.sh: |
    #! /usr/bin/env bash

    ## Accumulo logs directory. Referenced by logger config.
    export ACCUMULO_LOG_DIR="${ACCUMULO_LOG_DIR:-${basedir}/logs}"
    ## Zookeeper installation
    export ZOOKEEPER_HOME="${ZOOKEEPER_HOME:-/path/to/zookeeper}"

    ## Verify that Hadoop & Zookeeper installation directories exist
    if [[ ! -d "$ZOOKEEPER_HOME" ]]; then
    echo "ZOOKEEPER_HOME=$ZOOKEEPER_HOME is not set to a valid directory in accumulo-env.sh"
    exit 1
    fi

    ## Build using existing CLASSPATH, conf/ directory, dependencies in lib/, and external Hadoop & Zookeeper dependencies
    if [[ -n "$CLASSPATH" ]]; then
    CLASSPATH="${CLASSPATH}:${conf}"
    else
    CLASSPATH="${conf}"
    fi
    CLASSPATH="${CLASSPATH}:${lib}/*:${s3lib}/*:${ZOOKEEPER_HOME}/*"
    CLASSPATH="${CLASSPATH}:${ZOOKEEPER_HOME}/lib/*"
    export CLASSPATH

    ##################################################################
    # Build JAVA_OPTS variable. Defaults below work but can be edited.
    ##################################################################
    JAVA_OPTS=($ACCUMULO_JAVA_OPTS
      '-XX:OnOutOfMemoryError=kill -9 %p'
      '-XX:-OmitStackTraceInFastThrow'
      '-Djava.net.preferIPv4Stack=true'
      "-Daccumulo.native.lib.path=${lib}/native")

    ## Make sure Accumulo native libraries are built since they are enabled by default
    "${bin}"/accumulo-util build-native &> /dev/null

    ## JVM options set for individual applications
    case "$cmd" in
      manager|master)  JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.manager.javaOpts.memory }}) ;;
      monitor) JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.monitor.javaOpts.memory }}) ;;
      gc)      JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.gc.javaOpts.memory }}) ;;
      tserver) JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.tserver.javaOpts.memory }}) ;;
      compaction-coordinator) JAVA_OPTS=("${JAVA_OPTS[@]}" '-Xmx512m' '-Xms512m') ;;
      compactor) JAVA_OPTS=("${JAVA_OPTS[@]}" '-Xmx256m' '-Xms256m') ;;
      *)       JAVA_OPTS=("${JAVA_OPTS[@]}" '-Xmx256m' '-Xms64m') ;;
    esac

    ## JVM options set for logging. Review log4j2.properties file to see how they are used.
    JAVA_OPTS=("${JAVA_OPTS[@]}"
      "-Daccumulo.log.dir=${ACCUMULO_LOG_DIR}"
      "-Daccumulo.application=${cmd}${ACCUMULO_SERVICE_INSTANCE}_$(hostname)"
      "-Daccumulo.metrics.service.instance=${ACCUMULO_SERVICE_INSTANCE}"
      "-Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector"
      "-Dotel.service.name=${cmd}${ACCUMULO_SERVICE_INSTANCE}"
    )

    case "$cmd" in
      monitor|gc|manager|master|tserver|compaction-coordinator|compactor)
        JAVA_OPTS=("${JAVA_OPTS[@]}" "-Dlog4j.configurationFile=log4j2-service.properties")
        ;;
      *)
        # let log4j use its default behavior (log4j2.properties, etc.)
        true
        ;;
    esac

    export MALLOC_ARENA_MAX=${MALLOC_ARENA_MAX:-1}

  accumulo.properties: |
    instance.volumes={{ .Values.accumulo.volumes }}
    
    # Configure FS implementations to be used by Accumulo
    general.volume.chooser=org.apache.accumulo.core.spi.fs.PreferredVolumeChooser
    general.custom.volume.preferred.default=s3a://{{ .Values.s3.bucket }}/accumulo
    general.custom.volume.preferred.logger=s3a://{{ .Values.s3.bucket }}/accumulo-wal
    manager.wal.closer.implementation=org.apache.accumulo.server.manager.recovery.S3LogCloser

    ## Sets location of Zookeepers
    instance.zookeeper.host={{ .Values.zookeeper.host }}

    ## Change secret before initialization. All Accumulo servers must have same secret
    instance.secret=DEFAULT

    ## Set to false if 'accumulo-util build-native' fails
    tserver.memory.maps.native.enabled=true

    ## Trace user
    trace.user=root

    ## Trace password
    trace.password=secret

  accumulo-client.properties: |
    instance.name={{ .Values.accumulo.instance_name }}
    instance.zookeepers={{ .Values.zookeeper.host }}
    #instance.zookeepers.timeout=30s
    auth.type=password
    auth.principal={{ .Values.accumulo.username }}
    auth.token={{ .Values.accumulo.passwd }}

  core-site.xml: |
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>s3a://accumulo</value>
        </property>
        <property>
            <name>fs.s3a.impl</name>
            <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
        </property>
        <property>
            <name>fs.s3a.downgrade.syncable.exceptions</name>
            <value>true</value>
        </property>
        <property>
            <name>fs.s3a.access.key</name>
            <value>{{ .Values.s3.key }}</value>
        </property>
        <property>
            <name>fs.s3a.secret.key</name>
            <value>{{ .Values.s3.secret }}</value>
        </property>

        {{ if .Values.s3.endpoint }}
        <property>
            <name>fs.s3a.endpoint</name>
            <value>{{ .Values.s3.endpoint }}</value>
        </property>
        {{ end }}
        {{ if .Values.s3.region }}
        <property>
            <name>fs.s3a.region</name>
            <value>{{ .Values.s3.region }}</value>
        </property>
        {{ end }}

        <property>
            <name>fs.s3a.connection.ssl.enabled</name>
            <value>false</value>
        </property>
        <!--
        <property>
          <name>fs.s3a.endpoint</name>
          <value></value>
        </property>
        <property>
          <name>fs.s3a.connection.ssl.enabled</name>
          <value>false</value>
        </property>
        -->
    </configuration>

  log4j.properties: |
    log4j.appender.console=org.apache.log4j.ConsoleAppender
    log4j.appender.console.Target=System.err
    log4j.appender.console.Threshold=ALL
    log4j.appender.console.layout.ConversionPattern=%d{ISO8601} [%-8c{2}] %-5p: %m%n
    log4j.appender.console.layout=org.apache.log4j.PatternLayout

    ## Hide audit logs generated by the shell
    log4j.logger.org.apache.accumulo.shell.Shell.audit=WARN

    ## Constrain some particularly spammy loggers
    log4j.logger.org.apache.accumulo.core.file.rfile.bcfile.Compression=WARN
    log4j.logger.org.apache.commons.vfs2.impl.DefaultFileSystemManager=WARN
    log4j.logger.org.apache.hadoop.io.compress=WARN
    log4j.logger.org.apache.zookeeper=ERROR

    ## Uncomment the following for detailed logging (for example, in the Shell)
    #log4j.logger.org.apache.accumulo.core=DEBUG

    ## Append most logs to console
    log4j.rootLogger=DEBUG, console

  bootstrap.sh: |
    #!/bin/bash

    # Directory to find config artifacts
    CONFIG_DIR="/tmp/accumulo-config"

    # Copy accumulo config files from volume mount
    for f in accumulo.properties accumulo-env.sh accumulo-client.properties log4j.properties core-site.xml; do
      if [[ -e ${CONFIG_DIR}/$f ]]; then
        cp ${CONFIG_DIR}/$f /opt/accumulo/conf/$f
      else
        echo "ERROR: Could not find $f in $CONFIG_DIR"
        exit 1
      fi
    done

    # add managers to the cluster.yaml
    manager_end=$(({{ .Values.accumulo.manager.replicas }} - 1))
    echo "manager:" >> /opt/accumulo/conf/cluster.yaml
    for i in $(seq 0 $manager_end);
      do
        echo "  - {{ template "accumulo.fullname" . }}-manager-$i" >> /opt/accumulo/conf/cluster.yaml;
    done
    echo "" >> /opt/accumulo/conf/cluster.yaml

    # add managers to the cluster.yaml
    tserver_end=$(({{ .Values.accumulo.tserver.replicas }} - 1))
    echo "tserver:" >> /opt/accumulo/conf/cluster.yaml
    for i in $(seq 0 $tserver_end);
      do
        echo "  - {{ template "accumulo.fullname" . }}-ts-$i" >> /opt/accumulo/conf/cluster.yaml;
    done
    echo "" >> /opt/accumulo/conf/cluster.yaml

    # add monitor and gc to the cluster.yaml
    echo "monitor:" >> /opt/accumulo/conf/cluster.yaml
    echo "  - {{ template "accumulo.fullname" . }}-manager-0" >> /opt/accumulo/conf/cluster.yaml;
    echo "" >> /opt/accumulo/conf/cluster.yaml

    echo "gc:" >> /opt/accumulo/conf/cluster.yaml
    echo "  - {{ template "accumulo.fullname" . }}-manager-0" >> /opt/accumulo/conf/cluster.yaml;
    echo "" >> /opt/accumulo/conf/cluster.yaml

  manager.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo-service manager start
    tail -f /opt/accumulo/logs/*

  tserver.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo-service tserver start
    tail -f /opt/accumulo/logs/*

  gc.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo-service gc start
    tail -f /opt/accumulo/logs/*

  monitor.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo-service monitor start
    /opt/accumulo/bin/accumulo-service trace start
    tail -f /opt/accumulo/logs/*

  init.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh

    # only run init container once even with multiple managers, so on the first manager pod only
    if [[ "${HOSTNAME}" =~ "accumulo-manager-0" ]]; then
      if {{ .Values.accumulo.init }}; then
        $ACCUMULO_HOME/bin/accumulo init \
        --force \
        --clear-instance-name \
        --instance-name {{ .Values.accumulo.instance_name }} \
        --password {{ .Values.accumulo.passwd }} \
        --user {{ .Values.accumulo.username }}
      fi
    fi

  ts-wait.sh: |
    #!/bin/bash

    echo "Waiting for manager on 9999..."
    while ! nc -v -z {{ template "accumulo.fullname" . }}-manager-0 9999; do
      sleep 0.1 # wait for 1/10 of the second before check again
      echo "still waiting..."
    done
    echo "done waiting..."

